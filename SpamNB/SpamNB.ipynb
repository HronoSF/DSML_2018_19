{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем и переименовываем колонки с цифер на их суть для наглядности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_table('SMSSpamCollection',header=None)\n",
    "df.rename(columns = {0: 'label', 1: 'message'}, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замапим для удобности названия классов на цифры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем предобработку текстов сообщений,как-то:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-приведем все до lowerCase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-разобьем на токены"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Пользуем двуграммы так как это добавит точности классификации,потому что 'good' и 'not good' вещи разные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-уберём служебные слова и местоимения (они только сбивать будут,их в каждом предложении полно,а смысловой нагрузки не несут) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-пользуем стеммер Портера,чтобы вернуть слова в начальную форму(одно и то же слово в разных формах все равно одно и то же слово)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessMessages(message,gram=2):\n",
    "    message=message.lower()\n",
    "    words=word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 1:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    stop_words=stopwords.words('english')\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [PorterStemmer().stem(word) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак,теперь нам нужен NB,гуглим,что есть по формулам:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)$$P(\\omega _{i}\\,|\\,c)=\\frac{W_{ic}}{\\Sigma _{{i}'\\in V} W^{_{{i}'c}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$W{_{{i}'c}}- количество\\,раз\\,сколько\\,i-ое\\,слово\\,встречается\\,в\\,докуметнах\\,класса\\,C$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$V-список\\,всех\\,уникальных\\,слов\\,(словарь\\,корпуса)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не подойдет,не адекватно поведет себя при встрече с новым словом,значение обнулится => документ неззя класифицировать, у него нулевая вероятность по всем классам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Юзаем сглаживание Лапласса(т.е.делаем вид,что видели уже слово хотя бы раз),потому что самое очевидное решение:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  \n",
    "$$P(\\omega _{i}\\,|\\,c)=\\frac{W_{ic}+1}{\\Sigma _{{i}'\\in V} (W^{_{{i}'c}}+1)}=\\frac{W_{ic}+1}{|V|+\\Sigma _{{i}'\\in V}W^{_{{i}'c}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пойдет,но слишком теория,какая формула по сути?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log\\frac{D_c}{D} + \\sum_{i \\in Q}\\log{\\frac{W_{ic}+1}{ |V|+L_{c} }}\\,\\,\\,(1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Где:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D_c-количество\\,документов\\,в\\,обучающей\\,выборке\\,принадлежащих\\,классу\\, с$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$D-общее\\,количество\\,докуметов\\,в\\,обучающей\\,выборке$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$|V|-количетсво\\,уникальных\\,слов\\,во\\,всех\\,документах\\,обучающей\\,выборки$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_{c}-суммарное\\,количество\\,слов\\,в\\,документах\\,класса\\,с\\,в\\,обучающей\\,выборке$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W_{ic}-сколько\\,раз\\,i-ое\\,слово\\,встречалось\\,в\\,документах\\,класса\\,с\\,в\\,обучающей\\,выборке$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q-множество\\,слов\\,классифицируемого\\,документа\\,(включая\\,повторы)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну вот теперь можно действовать,сделаем две штуки,с апдейтом веса слов(по идее,это должно добавить точности алгоритму)т.е.TF-IDF и без т.е.Bag of Words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В кратце о подходах:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Bag of words- модель,где мы высчитываем \"term freuency\" то есть количество появлений каждого слова в датасете:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\omega\\,|\\,Ham/Spam)=\\frac{Total\\,count\\,of\\,word\\,\\omega\\,in\\,Ham/Spam\\,messages }{Total\\,count\\,of\\,words\\,in\\,dataset}\\,\\,\\,(2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) TF-IDF(то есть Term Frequency-Inverse Documnet Frequency)-в дополнении к \"term frequency\" высчитываем \"inverse document frequency\":"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$IDF(\\omega)=log\\frac{Total\\,count\\,of\\,messages}{Total\\,count\\,of\\,messages\\,with\\, \\omega}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все равно не понятно,что считать-то? Яжпрограмист,конкретнее бы......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(\\omega\\,|\\,Ham/Spam)=\\frac{TF(\\omega\\,|\\,Ham/Spam)*IDF(\\omega)}{\\sum_{\\forall\\,words\\,x\\, \\in \\,train\\,dataset } TF(x\\,|\\,Ham/Spam)*IDF(x)}\\,\\,\\,(3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно и запрогать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBclassifier(object):\n",
    "    \n",
    "    def __init__(self, trainData,approach):\n",
    "        self.messages,self.label=trainData['message'],trainData['label']\n",
    "        self.approach=approach\n",
    "        \n",
    "    def fit(self):\n",
    "        #Высчитываем необходимые велечины:\n",
    "        self.neededDataForFormulas()\n",
    "        #Применяем выбранный метод:\n",
    "        if self.approach == 'Bag of Words':\n",
    "            self.BOW()\n",
    "        if self.approach== 'TF-IDF':\n",
    "            self.TF_IDF()\n",
    " \n",
    "\n",
    "    def neededDataForFormulas(self):\n",
    "        # Какое кол-во строк в DF:\n",
    "        countOfMessages=self.messages.shape[0]\n",
    "        #Кол-во Ham и Spam строк в DF:\n",
    "        self.countOfHamMessage=self.label.value_counts()[0]\n",
    "        self.countOfSpamMessage=self.label.value_counts()[1]\n",
    "        self.totalMessage=self.countOfHamMessage+self.countOfSpamMessage\n",
    "        #Кол-во Ham и Spam слов в DF:\n",
    "        self.spamWords=0\n",
    "        self.hamWords=0\n",
    "        #Частота встречи слов из Ham и Spam:\n",
    "        self.tfSpam=dict()\n",
    "        self.tfHam=dict()\n",
    "        self.idfSpam=dict()\n",
    "        self.idfHam=dict()\n",
    "        \n",
    "        for i in range(countOfMessages):\n",
    "            preprocessedMessage=preprocessMessages(self.messages[i])\n",
    "            #Лист для отслеживания,встречалось слово или нет:\n",
    "            cachedWords=list()\n",
    "            \n",
    "            for word in preprocessedMessage:\n",
    "                #Суммарное кол-во слов в сообщениях класса Ham/Spam:\n",
    "                if self.label[i]:\n",
    "                    self.tfSpam[word]=self.tfSpam.get(word,0) + 1\n",
    "                    self.spamWords +=1\n",
    "                else:\n",
    "                    self.tfHam[word]=self.tfHam.get(word,0) + 1\n",
    "                    self.hamWords +=1\n",
    "                # Кол-во уникальных слов во всех сообщениях:\n",
    "                if word not in cachedWords:\n",
    "                    cachedWords +=[word]\n",
    "                #Сколько раз i-тое слово встречалось в сообщениях Ham/Spam:\n",
    "            for word in cachedWords:\n",
    "                if self.label[i]:\n",
    "                    self.idfSpam[word]=self.idfSpam.get(word,0)+1\n",
    "                else:\n",
    "                     self.idfHam[word]=self.idfHam.get(word,0)+1\n",
    "                        \n",
    "    def BOW(self):\n",
    "        #Используем формулу (2),для вычисления вероятности слова:\n",
    "        self.probOfSpam = dict()\n",
    "        self.probOfHam = dict()\n",
    "        for word in self.tfSpam:\n",
    "            #Нормированная вероятность со сглаживанием Лапласса:\n",
    "            self.probOfSpam[word] = (self.tfSpam[word] + 1) / (self.countOfSpamMessage +len(list(self.tfSpam.keys())))\n",
    "        for word in self.tfHam:\n",
    "            #Нормированная вероятность со сглаживанием Лапласса:\n",
    "            self.probOfHam[word] = (self.tfHam[word] + 1) / (self.countOfHamMessage + len(list(self.tfHam.keys())))\n",
    "        #Вероятность встретить Spam/Ham сообщение:\n",
    "        self.probOfSpamMessage=self.countOfSpamMessage / self.totalMessage\n",
    "        self.probOfHamMessage =self.countOfHamMessage / self.totalMessage \n",
    "        \n",
    "        \n",
    "    def TF_IDF(self):\n",
    "        self.probOfSpam=dict()\n",
    "        self.probOfHam=dict()\n",
    "        self.summTF_IDFforSpam=0\n",
    "        self.summTF_IDFforHam=0\n",
    "        #Используем формулу (3),для вычисления вероятности слова:\n",
    "        for word in self.tfSpam:\n",
    "            #Числитель:\n",
    "            self.probOfSpam[word]=(self.tfSpam[word])*log((self.countOfSpamMessage+self.countOfHamMessage)/(self.idfSpam[word]+self.idfHam.get(word,0)))\n",
    "            #Знаменатель:\n",
    "            self.summTF_IDFforSpam +=self.probOfSpam[word]\n",
    "        for word in self.tfSpam:\n",
    "            #Нормированная вероятность со сглаживанием Лапласса:\n",
    "            self.probOfSpam[word]=(self.probOfSpam[word]+1)/(self.summTF_IDFforSpam+len(list(self.probOfSpam.keys())))\n",
    "            \n",
    "        for word in self.tfHam:\n",
    "            #Числитель:\n",
    "            self.probOfHam[word]=(self.tfHam[word])*log((self.countOfSpamMessage+self.countOfHamMessage)/(self.idfHam[word]+self.idfSpam.get(word,0)))\n",
    "            #Знаменатель:\n",
    "            self.summTF_IDFforHam +=self.probOfHam[word]\n",
    "            #Нормированная вероятность со сглаживанием Лапласса:\n",
    "        for word in self.tfHam:\n",
    "            self.probOfHam[word]=(self.probOfHam[word]+1)/(self.summTF_IDFforHam+len(list(self.probOfHam.keys())))\n",
    "        #Вероятность встретить Spam/Ham сообщение:\n",
    "        self.probOfSpamMessage=self.countOfSpamMessage/self.totalMessage\n",
    "        self.probOfHamMessage=self.countOfHamMessage/self.totalMessage\n",
    "        \n",
    "        \n",
    "    def classify(self,preprocessedMessage):\n",
    "        pSpam=0\n",
    "        pHam=0\n",
    "        if (self.approach=='Bag of Words'):\n",
    "            for word in preprocessedMessage:\n",
    "                if word in self.probOfSpam:\n",
    "                    #Отдельный от суммы log в формуле (1)\n",
    "                    pSpam+=log(self.probOfSpam[word])\n",
    "                else:\n",
    "                    pSpam-=log(self.spamWords+ len(list(self.probOfSpam.keys())))\n",
    "                if word in self.probOfHam:\n",
    "                    #Отдельный от суммы log в формуле (1)\n",
    "                    pHam+=log(self.probOfHam[word])\n",
    "                else:\n",
    "                    pHam-=log(self.hamWords+ len(list(self.probOfHam.keys())))\n",
    "                #Сумма log-мов из формулы (1):\n",
    "                pSpam+=log(self.probOfSpamMessage)\n",
    "                pHam+=log(self.probOfHamMessage)\n",
    "            return pSpam>=pHam\n",
    "        \n",
    "        if (self.approach=='TF-IDF'):\n",
    "            for word in preprocessedMessage:\n",
    "                if word in self.probOfSpam:\n",
    "                    #Отдельный от суммы log в формуле (1)\n",
    "                    pSpam+=log(self.probOfSpam[word])\n",
    "                else:\n",
    "                    pSpam-=log(self.summTF_IDFforSpam+len(list(self.probOfSpam.keys())))\n",
    "                if word in self.probOfHam:\n",
    "                    #Отдельный от суммы log в формуле (1)\n",
    "                    pHam+=log(self.probOfHam[word])\n",
    "                else:\n",
    "                    pHam-=log(self.summTF_IDFforHam+len(list(self.probOfHam.keys())))\n",
    "                #Сумма log-мов из формулы (1):\n",
    "                pSpam+=log(self.probOfSpamMessage)\n",
    "                pHam+=log(self.probOfHamMessage)\n",
    "            return pSpam>=pHam\n",
    "        \n",
    "    def predict(self,testData):\n",
    "        result=dict()\n",
    "        for (i,message) in enumerate(testData):\n",
    "            preprocessedMessages=preprocessMessages(message)\n",
    "            result[i]=int(self.classify(preprocessedMessages))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем для оценки качества банальную Accuracy и Roc Auc Score ибо она может объективно оценить качество модели в условии несбалансированности класов,а у нас сильная несбалансированность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    truePos, trueNeg, falsePos, falseNeg = 0, 0, 0, 0\n",
    "    for i in range(len(labels)):\n",
    "        truePos += int(labels[i] == 1 and predictions[i] == 1)\n",
    "        trueNeg += int(labels[i] == 0 and predictions[i] == 0)\n",
    "        falsePos += int(labels[i] == 0 and predictions[i] == 1)\n",
    "        falseNeg += int(labels[i] == 1 and predictions[i] == 0)\n",
    "    return ((truePos + trueNeg) / (truePos + trueNeg + falsePos + falseNeg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем Крос-Валидацию как было сказано и обучаем,попутно фиксируя всю точность,что получается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1115 1116 1117 ... 5569 5570 5571] TEST: [   0    1    2 ... 1112 1113 1114]\n",
      "Accuracy Bag of Words: 0.9479820627802691 ,ROC AUC bag of Words: 0.8494148187258008\n",
      "Accuracy TF-IDF: 0.9479820627802691 ,ROC AUC TF-IDF: 0.8518630260974507\n",
      "\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [1115 1116 1117 ... 2227 2228 2229]\n",
      "Accuracy Bag of Words: 0.9479820627802691 ,ROC AUC bag of Words: 0.8276865160848733\n",
      "Accuracy TF-IDF: 0.9497757847533632 ,ROC AUC TF-IDF: 0.8347787146664337\n",
      "\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [2230 2231 2232 ... 3341 3342 3343]\n",
      "Accuracy Bag of Words: 0.9425493716337523 ,ROC AUC bag of Words: 0.8166291866207442\n",
      "Accuracy TF-IDF: 0.9470377019748654 ,ROC AUC TF-IDF: 0.8317394974934441\n",
      "\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [3344 3345 3346 ... 4455 4456 4457]\n",
      "Accuracy Bag of Words: 0.9434470377019749 ,ROC AUC bag of Words: 0.8329586210588299\n",
      "Accuracy TF-IDF: 0.9452423698384201 ,ROC AUC TF-IDF: 0.8393688774690862\n",
      "\n",
      "TRAIN: [   0    1    2 ... 4455 4456 4457] TEST: [4458 4459 4460 ... 5569 5570 5571]\n",
      "Accuracy Bag of Words: 0.9470377019748654 ,ROC AUC bag of Words: 0.8376036439984342\n",
      "Accuracy TF-IDF: 0.952423698384201 ,ROC AUC TF-IDF: 0.8582932991708481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(df):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        train_index,test_index=list(train_index),list(test_index)\n",
    "        trainData = df.loc[train_index]\n",
    "        trainData.reset_index(inplace=True)\n",
    "        trainData.drop(['index'],axis=1,inplace=True)\n",
    "        testData = df.loc[test_index]\n",
    "        testData.reset_index(inplace=True)\n",
    "        testData.drop(['index'],axis=1,inplace=True)\n",
    "        \n",
    "        model=NBclassifier(trainData,'Bag of Words')\n",
    "        model.fit()\n",
    "        result=model.predict(testData['message'])\n",
    "        print(\"Accuracy Bag of Words:\",accuracy(testData['label'],np.array(list(result.values()))),\",ROC AUC bag of Words:\",roc_auc_score(testData['label'],np.array(list(result.values()))))\n",
    "    \n",
    "        model=NBclassifier(trainData,'TF-IDF')\n",
    "        model.fit()\n",
    "        result=model.predict(testData['message'])\n",
    "        print(\"Accuracy TF-IDF:\",accuracy(testData['label'],np.array(list(result.values()))),\",ROC AUC TF-IDF:\",roc_auc_score(testData['label'],np.array(list(result.values()))))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо сравнить с коробкой в sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf=Pipeline([('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1115 1116 1117 ... 5569 5570 5571] TEST: [   0    1    2 ... 1112 1113 1114]\n",
      "Accuracy TF-IDF: 0.9560538116591928 ROC_AUC TF_IDF: 0.8541666666666667\n",
      "\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [1115 1116 1117 ... 2227 2228 2229]\n",
      "Accuracy TF-IDF: 0.9596412556053812 ROC_AUC TF_IDF: 0.8404255319148937\n",
      "\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [2230 2231 2232 ... 3341 3342 3343]\n",
      "Accuracy TF-IDF: 0.9605026929982047 ROC_AUC TF_IDF: 0.8394160583941606\n",
      "\n",
      "TRAIN: [   0    1    2 ... 5569 5570 5571] TEST: [3344 3345 3346 ... 4455 4456 4457]\n",
      "Accuracy TF-IDF: 0.9515260323159784 ROC_AUC TF_IDF: 0.8269230769230769\n",
      "\n",
      "TRAIN: [   0    1    2 ... 4455 4456 4457] TEST: [4458 4459 4460 ... 5569 5570 5571]\n",
      "Accuracy TF-IDF: 0.9614003590664273 ROC_AUC TF_IDF: 0.8517241379310345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(df):\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        train_index,test_index=list(train_index),list(test_index)\n",
    "        trainData = df.loc[train_index]\n",
    "        trainData.reset_index(inplace=True)\n",
    "        trainData.drop(['index'],axis=1,inplace=True)\n",
    "        testData = df.loc[test_index]\n",
    "        testData.reset_index(inplace=True)\n",
    "        testData.drop(['index'],axis=1,inplace=True)\n",
    "        \n",
    "        clf.fit(trainData['message'],trainData['label'])\n",
    "        result=clf.predict(testData['message'])\n",
    "        print(\"Accuracy TF-IDF:\",accuracy(testData['label'],result),\"ROC_AUC TF_IDF:\",roc_auc_score(testData['label'],result))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормально получилось,правда медленно,но это уже совсем другая история...."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
